//
//  File: %sys-array.h
//  Summary: {Definitions for REBARR}
//  Project: "Rebol 3 Interpreter and Run-time (Ren-C branch)"
//  Homepage: https://github.com/metaeducation/ren-c/
//
//=////////////////////////////////////////////////////////////////////////=//
//
// Copyright 2012 REBOL Technologies
// Copyright 2012-2017 Ren-C Open Source Contributors
// REBOL is a trademark of REBOL Technologies
//
// See README.md and CREDITS.md for more information
//
// Licensed under the Lesser GPL, Version 3.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
// https://www.gnu.org/licenses/lgpl-3.0.html
//
//=////////////////////////////////////////////////////////////////////////=//
//
// A "Rebol Array" is a series of REBVAL values which is terminated by an
// END marker.  In R3-Alpha, the END marker was itself a full-sized REBVAL
// cell...so code was allowed to write one cell past the capacity requested
// when Make_Array() was called.  But this always had to be an END.
//
// In Ren-C, there is an implicit END marker just past the last cell in the
// capacity.  Allowing a SET_END() on this position could corrupt the END
// signaling slot, which only uses a bit out of a Reb_Header sized item to
// signal.  Use SET_SERIES_LEN() to safely terminate arrays and respect not
// writing if it's past capacity.
//
// While many operations are shared in common with REBSER, there is a
// (deliberate) type incompatibility introduced.  The type compatibility is
// implemented in a way that works in C or C++ (though it should be reviewed
// for strict aliasing compliance).  To get the underlying REBSER of a REBARR
// use the SER() operation.
//
// An ARRAY is the main place in the system where "relative" values come
// from, because all relative words are created during the copy of the
// bodies of functions.  The array accessors must err on the safe side and
// give back a relative value.  Many inspection operations are legal on
// a relative value, but it cannot be copied without a "specifier" FRAME!
// context (which is also required to do a GET_VAR lookup).
//

// !!! We generally want to use LINK(Filename, x) but that uses the STR()
// macro which is not defined in this file.  There's a bit of a circular
// dependency since %sys-string.h uses arrays for bookmarks; so having a
// special operation here is an easy workaround that still lets us make a
// lot of this central code inlinable.
//
#define LINK_FILENAME_HACK(s) \
    cast(const REBSTR*, s->link.any.node)


// HEAD, TAIL, and LAST refer to specific value pointers in the array.  An
// empty array should have an END marker in its head slot, and since it has
// no last value then ARR_LAST should not be called (this is checked in
// debug builds).  A fully constructed array should always have an END
// marker in its tail slot, which is one past the last position that is
// valid for writing a full REBVAL.

inline static RELVAL *ARR_AT(const_if_c REBARR *a, REBLEN n)
  { return SER_AT(RELVAL, a, n); }

inline static RELVAL *ARR_HEAD(const_if_c REBARR *a)
  { return SER_HEAD(RELVAL, a); }

inline static RELVAL *ARR_TAIL(const_if_c REBARR *a)
  { return SER_TAIL(RELVAL, a); }

inline static RELVAL *ARR_LAST(const_if_c REBARR *a)
  { return SER_LAST(RELVAL, a); }

inline static RELVAL *ARR_SINGLE(const_if_c REBARR *a) {
    assert(not IS_SER_DYNAMIC(a));
    return cast(RELVAL*, &a->content.fixed);
}

#ifdef __cplusplus
    inline static const RELVAL *ARR_AT(const REBARR *a, REBLEN n)
        { return SER_AT(const RELVAL, a, n); }

    inline static const RELVAL *ARR_HEAD(const REBARR *a)
        { return SER_HEAD(const RELVAL, a); }

    inline static const RELVAL *ARR_TAIL(const REBARR *a)
        { return SER_TAIL(const RELVAL, a); }

    inline static const RELVAL *ARR_LAST(const REBARR *a)
        { return SER_LAST(const RELVAL, a); }

    inline static const RELVAL *ARR_SINGLE(const REBARR *a) {
        assert(not IS_SER_DYNAMIC(a));
        return cast(const RELVAL*, &a->content.fixed);
    }
#endif


// It's possible to calculate the array from just a cell if you know it's a
// cell inside a singular array.
//
inline static REBARR *Singular_From_Cell(const RELVAL *v) {
    REBARR *singular = ARR(  // some checking in debug builds is done by ARR()
        cast(void*,
            cast(REBYTE*, m_cast(RELVAL*, v))
            - offsetof(struct Reb_Series, content)
        )
    );
    assert(not IS_SER_DYNAMIC(singular));
    return singular;
}

// As with an ordinary REBSER, a REBARR has separate management of its length
// and its terminator.  Many routines seek to choose the precise moment to
// sync these independently for performance reasons (for better or worse).
//
inline static REBLEN ARR_LEN(const REBARR *a)
  { return SER_USED(a); }


inline static void RESET_ARRAY(REBARR *a) {
    SET_SERIES_LEN(a, 0);
}


//
// REBVAL cells cannot be written to unless they carry CELL_FLAG_CELL, and
// have been "formatted" to convey their lifetime (stack or array).  This
// helps debugging, but is also important information needed by Move_Value()
// for deciding if the lifetime of a target cell requires the "reification"
// of any temporary referenced structures into ones managed by the GC.
//
// Performance-wise, the prep process requires writing one `uintptr_t`-sized
// header field per cell.  For fully optimum efficiency, clients filling
// arrays can initialize the bits as part of filling in cells vs. using
// Prep_Array.  This is done by the evaluator when building the f->varlist for
// a frame (it's walking the parameters anyway).  However, this is usually
// not necessary--and sacrifices generality for code that wants to work just
// as well on stack values and heap values.
//
inline static void Prep_Array(
    REBARR *a,
    REBLEN capacity_plus_one // Expand_Series passes 0 on dynamic reallocation
){
    assert(IS_SER_DYNAMIC(a));

    RELVAL *prep = ARR_HEAD(a);

    if (NOT_SERIES_FLAG(a, FIXED_SIZE)) {
        //
        // Expandable arrays prep all cells, including in the not-yet-used
        // capacity.  Otherwise you'd waste time prepping cells on every
        // expansion and un-prepping them on every shrink.
        //
        REBLEN n;
        for (n = 0; n < a->content.dynamic.rest - 1; ++n, ++prep)
            Prep_Cell(prep);
    }
    else {
        assert(capacity_plus_one != 0);

        REBLEN n;
        for (n = 1; n < capacity_plus_one; ++n, ++prep)
            Prep_Cell(prep);  // have to prep cells in useful capacity

        // If an array isn't expandable, let the release build not worry
        // about the bits in the excess capacity.  But set them to trash in
        // the debug build.
        //
        prep->header.bits = Endlike_Header(0); // unwritable
        USED(TRACK_CELL_IF_DEBUG(prep));
      #if !defined(NDEBUG)
        while (n < a->content.dynamic.rest) { // no -1 (n is 1-based)
            ++n;
            prep = TRACK_CELL_IF_DEBUG(prep + 1);
            prep->header.bits =
                FLAG_KIND3Q_BYTE(REB_T_TRASH)
                | FLAG_HEART_BYTE(REB_T_TRASH); // unreadable
        }
      #endif

        // Currently, release build also puts an unreadable end at capacity.
        // It may not be necessary, but doing it for now to have an easier
        // invariant to work with.  Review.
        //
        prep = ARR_AT(a, a->content.dynamic.rest - 1);
        // fallthrough
    }

    // Although currently all dynamically allocated arrays use a full REBVAL
    // cell for the end marker, it could use everything except the second byte
    // of the first `uintptr_t` (which must be zero to denote end).  To make
    // sure no code depends on a full cell in the last location,  make it
    // an unwritable end--to leave flexibility to use the rest of the cell.
    //
    prep->header.bits = Endlike_Header(0);
    USED(TRACK_CELL_IF_DEBUG(prep));
}


// Make a series that is the right size to store REBVALs (and marked for the
// garbage collector to look into recursively).  ARR_LEN() will be 0.
//
inline static REBARR *Make_Array_Core(REBLEN capacity, REBFLGS flags) {
    const REBLEN wide = sizeof(REBVAL);

    REBSER *s = Alloc_Series_Node(flags | SERIES_FLAG_IS_ARRAY);

    if (
        (flags & SERIES_FLAG_DYNAMIC)  // inlining will constant fold
        or capacity > 1
    ){
        capacity += 1;  // account for cell needed for terminator (END)

        SET_SERIES_FLAG(s, DYNAMIC);

        if (not Did_Series_Data_Alloc(s, capacity)) {  // expects USED_BYTE=255
            s->leader.bits &= ~NODE_FLAG_MANAGED;  // can't kill if managed
            SET_SERIES_FLAG(s, INACCESSIBLE);
            GC_Kill_Series(s);  // ^-- needs non-null data unless INACCESSIBLE

            fail (Error_No_Memory(capacity * wide));
        }

        Prep_Array(ARR(s), capacity);
        SET_END(ARR_HEAD(ARR(s)));

      #if defined(DEBUG_COLLECT_STATS)
        PG_Reb_Stats->Series_Memory += capacity * wide;
      #endif
    }
    else {
        RELVAL *cell = TRACK_CELL_IF_DEBUG(SER_CELL(s));
        cell->header.bits = CELL_MASK_PREP_END;
    }

    s->info.bits = Endlike_Header(
        FLAG_WIDE_BYTE_ARRAY()  // reserved for future use
            | FLAG_USED_BYTE_ARRAY()  // also reserved
    );

    // It is more efficient if you know a series is going to become managed to
    // create it in the managed state.  But be sure no evaluations are called
    // before it's made reachable by the GC, or use PUSH_GC_GUARD().
    //
    // !!! Code duplicated in Make_Series_Core ATM.
    //
    if (not (flags & NODE_FLAG_MANAGED)) {  // most callsites const fold this
        if (SER_FULL(GC_Manuals))
            Extend_Series(GC_Manuals, 8);

        cast(REBSER**, GC_Manuals->content.dynamic.data)[
            GC_Manuals->content.dynamic.used++
        ] = s;  // start with NODE_FLAG_MANAGED to not need to remove later
    }

    // Arrays created at runtime default to inheriting the file and line
    // number from the array executing in the current frame.
    //
    if (flags & ARRAY_FLAG_HAS_FILE_LINE_UNMASKED) { // most callsites fold
        assert(flags & SERIES_FLAG_LINK_NODE_NEEDS_MARK);
        if (
            not FRM_IS_VARIADIC(FS_TOP) and
            GET_ARRAY_FLAG(FRM_ARRAY(FS_TOP), HAS_FILE_LINE_UNMASKED)
        ){
            mutable_LINK(Filename, s) = LINK_FILENAME_HACK(FRM_ARRAY(FS_TOP));
            s->misc.line = FRM_ARRAY(FS_TOP)->misc.line;
        }
        else {
            CLEAR_ARRAY_FLAG(ARR(s), HAS_FILE_LINE_UNMASKED);
            CLEAR_SERIES_FLAG(s, LINK_NODE_NEEDS_MARK);
        }
    }

  #if defined(DEBUG_COLLECT_STATS)
    PG_Reb_Stats->Blocks++;
  #endif

    assert(ARR_LEN(cast(REBARR*, s)) == 0);
    return cast(REBARR*, s);
}

#define Make_Array(capacity) \
    Make_Array_Core((capacity), ARRAY_MASK_HAS_FILE_LINE)

// !!! Currently, many bits of code that make copies don't specify if they are
// copying an array to turn it into a paramlist or varlist, or to use as the
// kind of array the use might see.  If we used plain Make_Array() then it
// would add a flag saying there were line numbers available, which may
// compete with the usage of the ->misc and ->link fields of the series node
// for internal arrays.
//
inline static REBARR *Make_Array_For_Copy(
    REBLEN capacity,
    REBFLGS flags,
    const REBARR *original
){
    if (original and GET_ARRAY_FLAG(original, NEWLINE_AT_TAIL)) {
        //
        // All of the newline bits for cells get copied, so it only makes
        // sense that the bit for newline on the tail would be copied too.
        //
        flags |= ARRAY_FLAG_NEWLINE_AT_TAIL;
    }

    if (
        (flags & ARRAY_FLAG_HAS_FILE_LINE_UNMASKED)
        and (original and GET_ARRAY_FLAG(original, HAS_FILE_LINE_UNMASKED))
    ){
        REBARR *a = Make_Array_Core(
            capacity,
            flags & ~ARRAY_FLAG_HAS_FILE_LINE_UNMASKED
        );
        mutable_LINK(Filename, a) = LINK_FILENAME_HACK(original);
        a->misc.line = original->misc.line;
        SET_ARRAY_FLAG(a, HAS_FILE_LINE_UNMASKED);
        return a;
    }

    return Make_Array_Core(capacity, flags);
}


// A singular array is specifically optimized to hold *one* value in a REBSER
// node directly, and stay fixed at that size.
//
// Note ARR_SINGLE() must be overwritten by the caller...it contains an END
// marker but the array length is 1, so that will assert if you don't.
//
// For `flags`, be sure to consider if you need ARRAY_FLAG_HAS_FILE_LINE.
//
inline static REBARR *Alloc_Singular(REBFLGS flags) {
    assert(not (flags & SERIES_FLAG_DYNAMIC));
    return Make_Array_Core(1, flags | SERIES_FLAG_FIXED_SIZE);
}

#define Append_Value(a,v) \
    Move_Value(Alloc_Tail_Array(a), (v))

#define Append_Value_Core(a,v,s) \
    Derelativize(Alloc_Tail_Array(a), (v), (s))

// Modes allowed by Copy_Block function:
enum {
    COPY_SHALLOW = 1 << 0,
    COPY_DEEP = 1 << 1, // recurse into arrays
    COPY_STRINGS = 1 << 2,
    COPY_OBJECT = 1 << 3,
    COPY_SAME = 1 << 4
};

#define COPY_ALL \
    (COPY_DEEP | COPY_STRINGS)


#define Copy_Values_Len_Shallow(v,s,l) \
    Copy_Values_Len_Extra_Shallow_Core((v), (s), (l), 0, 0)

#define Copy_Values_Len_Shallow_Core(v,s,l,f) \
    Copy_Values_Len_Extra_Shallow_Core((v), (s), (l), 0, (f))

#define Copy_Values_Len_Extra_Shallow(v,s,l,e) \
    Copy_Values_Len_Extra_Shallow_Core((v), (s), (l), (e), 0) 


#define Copy_Array_Shallow(a,s) \
    Copy_Array_At_Shallow((a), 0, (s))

#define Copy_Array_Shallow_Flags(a,s,f) \
    Copy_Array_At_Extra_Shallow((a), 0, (s), 0, (f))

#define Copy_Array_Deep_Managed(a,s) \
    Copy_Array_At_Extra_Deep_Flags_Managed((a), 0, (s), 0, SERIES_FLAGS_NONE)

#define Copy_Array_Deep_Flags_Managed(a,s,f) \
    Copy_Array_At_Extra_Deep_Flags_Managed((a), 0, (s), 0, (f))

#define Copy_Array_At_Deep_Managed(a,i,s) \
    Copy_Array_At_Extra_Deep_Flags_Managed((a), (i), (s), 0, SERIES_FLAGS_NONE)

#define COPY_ANY_ARRAY_AT_DEEP_MANAGED(v) \
    Copy_Array_At_Extra_Deep_Flags_Managed( \
        VAL_ARRAY(v), VAL_INDEX(v), VAL_SPECIFIER(v), 0, SERIES_FLAGS_NONE)

#define Copy_Array_At_Shallow(a,i,s) \
    Copy_Array_At_Extra_Shallow((a), (i), (s), 0, SERIES_FLAGS_NONE)

#define Copy_Array_Extra_Shallow(a,s,e) \
    Copy_Array_At_Extra_Shallow((a), 0, (s), (e), SERIES_FLAGS_NONE)

// See TS_NOT_COPIED for the default types excluded from being deep copied
//
inline static REBARR* Copy_Array_At_Extra_Deep_Flags_Managed(
    const REBARR *original, // ^-- not macro because original mentioned twice
    REBLEN index,
    REBSPC *specifier,
    REBLEN extra,
    REBFLGS flags
){
    return Copy_Array_Core_Managed(
        original,
        index, // at
        specifier,
        ARR_LEN(original), // tail
        extra, // extra
        flags, // note no ARRAY_HAS_FILE_LINE by default
        TS_SERIES & ~TS_NOT_COPIED // types
    );
}


//=////////////////////////////////////////////////////////////////////////=//
//
//  ANY-ARRAY! (uses `struct Reb_Any_Series`)
//
//=////////////////////////////////////////////////////////////////////////=//
//
// See %sys-bind.h
//

#define EMPTY_BLOCK \
    Root_Empty_Block

#define EMPTY_ARRAY \
    PG_Empty_Array // Note: initialized from VAL_ARRAY(Root_Empty_Block)


// These operations do not need to take the value's index position into
// account; they strictly operate on the array series
//
inline static const REBARR *VAL_ARRAY(REBCEL(const*) v) {
    assert(ANY_ARRAY_KIND(CELL_HEART(v)));

    const REBARR *a = ARR(VAL_NODE1(v));
    if (GET_SERIES_FLAG(a, INACCESSIBLE))
        fail (Error_Series_Data_Freed_Raw());
    return a;
}

#define VAL_ARRAY_ENSURE_MUTABLE(v) \
    m_cast(REBARR*, VAL_ARRAY(ENSURE_MUTABLE(v)))

#define VAL_ARRAY_KNOWN_MUTABLE(v) \
    m_cast(REBARR*, VAL_ARRAY(KNOWN_MUTABLE(v)))


// These array operations take the index position into account.  The use
// of the word AT with a missing index is a hint that the index is coming
// from the VAL_INDEX() of the value itself.
//
// IMPORTANT: This routine will trigger a failure if the array index is out
// of bounds of the data.  If a function can deal with such out of bounds
// arrays meaningfully, it should work with VAL_INDEX_UNBOUNDED().
//
inline static const RELVAL *VAL_ARRAY_LEN_AT(
    option(REBLEN*) len_at_out,
    REBCEL(const*) v
){
    const REBARR *arr = VAL_ARRAY(v);
    REBIDX i = VAL_INDEX_RAW(v);  // VAL_ARRAY() already checks it's series
    REBLEN len = ARR_LEN(arr);
    if (i < 0 or i > cast(REBIDX, len))
        fail (Error_Index_Out_Of_Range_Raw());
    if (len_at_out)  // inlining should remove this if() for VAL_ARRAY_AT()
        *unwrap(len_at_out) = len - i;
    return ARR_AT(arr, i);
}

#define VAL_ARRAY_AT(v) \
    VAL_ARRAY_LEN_AT(nullptr, (v))

inline static const RELVAL *VAL_ARRAY_AT_T(
    option(const RELVAL**) tail_out,
    REBCEL(const*) v
){
    const REBARR *arr = VAL_ARRAY(v);
    REBIDX i = VAL_INDEX_RAW(v);  // VAL_ARRAY() already checks it's series
    REBLEN len = ARR_LEN(arr);
    if (i < 0 or i > cast(REBIDX, len))
        fail (Error_Index_Out_Of_Range_Raw());
    const RELVAL *at = ARR_AT(arr, i);
    if (tail_out)  // inlining should remove this if() for no tail
        *unwrap(tail_out) = at + (len - i);
    return at;
}

inline static const RELVAL *VAL_ARRAY_AT_HEAD_T(
    option(const RELVAL**) tail_out,
    REBCEL(const*) v
){
    const REBARR *arr = VAL_ARRAY(v);
    REBIDX i = VAL_INDEX_RAW(v);  // VAL_ARRAY() already checks it's series
    const RELVAL *at = ARR_AT(arr, i);
    if (tail_out) {  // inlining should remove this if() for no tail
        REBLEN len = ARR_LEN(arr);
        *unwrap(tail_out) = at + len;
    }
    return at;
}


#define VAL_ARRAY_AT_ENSURE_MUTABLE(v) \
    m_cast(RELVAL*, VAL_ARRAY_AT(ENSURE_MUTABLE(v)))

#define VAL_ARRAY_KNOWN_MUTABLE_AT(v) \
    m_cast(RELVAL*, VAL_ARRAY_AT(KNOWN_MUTABLE(v)))

#define VAL_ARRAY_KNOWN_MUTABLE_LEN_AT(len_out,v) \
    m_cast(RELVAL*, VAL_ARRAY_LEN_AT((len_out), KNOWN_MUTABLE(v)))

// !!! R3-Alpha introduced concepts of immutable series with PROTECT, but
// did not consider the protected status to apply to binding.  Ren-C added
// more notions of immutability (const, holds, locking/freezing) and enforces
// it at compile-time...which caught many bugs.  But being able to bind
// "immutable" data was mechanically required by R3-Alpha for efficiency...so
// new answers will be needed.  See Virtual_Bind_Deep_To_New_Context() for
// some of the thinking on this topic.  Until it's solved, binding-related
// calls to this function get mutable access on non-mutable series.  :-/
//
#define VAL_ARRAY_AT_MUTABLE_HACK(v) \
    m_cast(RELVAL*, VAL_ARRAY_AT(v))

#define VAL_ARRAY_TAIL(v) \
  ARR_TAIL(VAL_ARRAY(v))


// !!! VAL_ARRAY_AT_HEAD() is a leftover from the old definition of
// VAL_ARRAY_AT().  Unlike SKIP in Rebol, this definition did *not* take
// the current index position of the value into account.  It rather extracted
// the array, counted from the head, and disregarded the index entirely.
//
// The best thing to do with it is probably to rewrite the use cases to
// not need it.  But at least "AT HEAD" helps communicate what the equivalent
// operation in Rebol would be...and you know it's not just giving back the
// head because it's taking an index.  So  it looks weird enough to suggest
// looking here for what the story is.
//
inline static const RELVAL *VAL_ARRAY_AT_HEAD(
    const RELVAL *v,
    REBLEN n
){
    const REBARR *a = VAL_ARRAY(v);  // debug build checks it's ANY-ARRAY!
    if (n > ARR_LEN(a))
        fail (Error_Index_Out_Of_Range_Raw());
    return ARR_AT(a, (n));
}

//=//// ANY-ARRAY! INITIALIZER HELPERS ////////////////////////////////////=//
//
// Declaring as inline with type signature ensures you use a REBARR* to
// initialize, and the C++ build can also validate managed consistent w/const.

inline static REBVAL *Init_Any_Array_At_Core(
    RELVAL *out,
    enum Reb_Kind kind,
    const_if_c REBARR *array,
    REBLEN index,
    REBARR *binding
){
    return Init_Any_Series_At_Core(
        out,
        kind,
        Force_Series_Managed_Core(array),
        index,
        binding
    );
}

#ifdef __cplusplus
    inline static REBVAL *Init_Any_Array_At_Core(
        RELVAL *out,
        enum Reb_Kind kind,
        const REBARR *array,  // all const arrays should be already managed
        REBLEN index,
        REBARR *binding
    ){
        return Init_Any_Series_At_Core(out, kind, array, index, binding);
    }
#endif

#define Init_Any_Array_At(v,t,a,i) \
    Init_Any_Array_At_Core((v), (t), (a), (i), UNBOUND)

#define Init_Any_Array(v,t,a) \
    Init_Any_Array_At((v), (t), (a), 0)

#define Init_Block(v,s)     Init_Any_Array((v), REB_BLOCK, (s))
#define Init_Group(v,s)     Init_Any_Array((v), REB_GROUP, (s))


inline static RELVAL *Init_Relative_Block_At(
    RELVAL *out,
    REBACT *action,  // action to which array has relative bindings
    REBARR *array,
    REBLEN index
){
    RELVAL *block = RESET_CELL(out, REB_BLOCK, CELL_FLAG_FIRST_IS_NODE);
    INIT_VAL_NODE1(block, array);
    VAL_INDEX_RAW(block) = index;
    INIT_SPECIFIER(block, action);
    return out;
}

#define Init_Relative_Block(out,action,array) \
    Init_Relative_Block_At((out), (action), (array), 0)


// The rule for splicing is now fixed as "only plain BLOCK! splices":
// https://forum.rebol.info/t/1332
//
// Despite the simple contract, using a call to this routine helps document
// placs where the decision to splice or not is being made.
//
#define Splices_Without_Only(v) \
    IS_BLOCK(v)


// Checks if ANY-GROUP! is like ((...)) or (...), used by COMPOSE & PARSE
//
inline static bool Is_Any_Doubled_Group(REBCEL(const*) group) {
    assert(ANY_GROUP_KIND(CELL_HEART(group)));
    const RELVAL *inner = VAL_ARRAY_AT(group);
    if (KIND3Q_BYTE(inner) != REB_GROUP or NOT_END(inner + 1))
        return false; // plain (...) GROUP!
    return true; // a ((...)) GROUP!, inject as rule
}


#ifdef NDEBUG
    #define ASSERT_ARRAY(s)     NOOP
    #define ASSERT_SERIES(s)    NOOP
#else
    #define ASSERT_ARRAY(s) \
        Assert_Array_Core(s)

    static inline void ASSERT_SERIES(const REBSER *s) {
        if (IS_SER_ARRAY(s))
            Assert_Array_Core(ARR(s));
        else
            Assert_Series_Core(s);
    }

    #define IS_VALUE_IN_ARRAY_DEBUG(a,v) \
        (ARR_LEN(a) != 0 and (v) >= ARR_HEAD(a) and (v) < ARR_TAIL(a))
#endif


#undef LINK_FILENAME_HACK  // later files shoul use LINK(Filename, x)
