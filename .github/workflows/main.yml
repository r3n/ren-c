#
# main.yml
#
# GitHub Actions Workflow for building the Wasm version of Ren-C.  It builds
# all pull requests to master, but only deploys commits that are accepted to
# the master branch.
#
# Deployments will become "live" in the Web REPL demonstration directly from
# this action...but only if they are "greenlit" after running a test in a
# headless Firefox browser that is automated via Python and "Marionette".
#
# Bash Style Ideas:
#
# https://ae1020.github.io/thoughts-on-bash-style/
#
# Links for future investigation:
#
# https://github.com/fkirc/skip-duplicate-actions
#

name: CI


# Controls when the action will run.  Currently we use the default to trigger
# the workflow on push or pull request events, but only for the master branch.
#
on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

  workflow_dispatch:  # Allows running this workflow manually from Actions tab


# Environment variables can be set per step, per job, or for entire workflow.
# But if you want to dynamically set a variable that survives between steps,
# you have to use the syntax:
#
#     echo "VAR=value" >> $GITHUB_ENV
#
# It will be available in the ensuing steps (though not the current one).
#
# https://docs.github.com/en/free-pro-team@latest/actions/reference/environment-variables
#
# Note: If you see files advocating for a syntax like `::set-env::` that is
# a deprecated method:
#
# https://github.blog/changelog/2020-10-01-github-actions-deprecating-set-env-and-add-path-commands/
#
env:
  AWS_S3_BUCKET_NAME: metaeducation


# Each "Job" runs in its own VM, and a workflow run is made up of one or more
# jobs that can run sequentially or in parallel.
#
# Jobs are isolated from one another (outside of any data they might exchange
# indirectly through uploading and downloading from the network).  This means
# you can't have a "build job" and a "deploy job" that uploads the build
# products of that job, since the deploy wouldn't have access to any of the
# files that were built.  "Steps" must be used.
#
jobs:
  web-build:  # Name of this workflow's only job

    # The type of runner that the job will run on.  Options listed here:
    #
    # https://github.com/actions/virtual-environments#available-environments
    #
    runs-on: ubuntu-20.04


    # The "matrix" ability of GitHub actions lets you permute some standard
    # properties (like versions of node.js), but it doesn't directly let you
    # set a matrix of environment variables.  You have to go through a level
    # of indirection to set "matrix include variables", and then adjust those
    # in a job step to be environment variables.
    #
    # https://docs.github.com/en/free-pro-team@latest/actions/reference/workflow-syntax-for-github-actions#using-environment-variables-in-a-matrix
    #
    # Note: This matrix once included `0.16.2` for a pthreads enabled build,
    # but that was omitted for simplicity.  The matrix scaffolding is left
    # here to show how it would be done if another build variation was needed.
    #
    strategy:
      matrix:
       include:
         - os-id: 0.16.1  # "asyncify" Emscripten build (only variant ATM)
           config-file: emscripten.r


    # Steps are a sequence of tasks that will be executed within a single VM
    # as part of the job.
    #
    # If a step fails, then the default behavior is for the subsequent steps
    # to not run, though this can be overridden with an `if:` property, which
    # is granular enough to allow running only if particular other steps
    # have completed:
    #
    # https://docs.github.com/en/free-pro-team@latest/actions/reference/context-and-expression-syntax-for-github-actions#job-status-check-functions
    # https://stackoverflow.com/a/61832535
    #
    # Each step has its own isolated environment variables, but it is possible
    # to export state seen by future steps (see `environment:` notes above)
    #
    # The exit status of a step is the result of the last executed command in
    # that step, or the parameter to `exit` if the step ends prematurely.
    #
    # A step that only contains `uses:` is a means of incorporating a fragment
    # of GitHub action code published in a separate repository.  Link to that
    # repository in a comment so that the options (if any) are at hand.
    #
    steps:  # (no indentatation needed below; so indent the minimum!)


  ##### BUILD STEPS ##########################################################

    # We build both pull requests and commits to master.  So the build steps
    # are run unconditionally (no `if:` qualifiers)


    # The checkout action checks-out your repository under $GITHUB_WORKSPACE
    #
    # https://github.com/actions/checkout
    #
    # Note: This strangely starts you up in a directory:
    #
    #      /home/runner/work/ren-c/ren-c
    #
    # The parent directory appears to contain the same files.  It's not clear
    # why it's done this way...but presumably it's on purpose.
    #
    - uses: actions/checkout@v2


    # This action will install the Emscripten SDK, which makes the `emcc`
    # compilation command available.  This compiler takes in C files and will
    # emit wasm, for producing libr3.js
    #
    # https://github.com/mymindstorm/setup-emsdk
    #
    - uses: mymindstorm/setup-emsdk@v7


    # See note in `strategy: matrix:` about why we have to do this.
    #
    - name: Convert Matrix Variables To Environment Variables
      run: |
        echo "OS_ID=${{ matrix.os-id }}" >> $GITHUB_ENV
        echo "CONFIG_FILE=${{ matrix.config-file }}" >> $GITHUB_ENV


    # Show a little bit of sanity check information
    #
    - name: Output System Information
      run: |
        echo "Current directory is: $(pwd)"
        ls
        echo "Parent directory contents:"
        ls
        echo "EMCC version check:"
        emcc -v


    # Grab abbreviated and full git commit ID into environment variables.
    # The full commit is passed to make to build into the binary, and the
    # abbreviated commit is used to name the executable.
    #
    # http://stackoverflow.com/a/42549385
    #
    # (While GitHub Actions may offer this, good to have it done in an
    # agnostic fashion so the script is more portable)
    #
    - name: Grab Git Hash and Short Hash Into Environment Variables
      run: |
        git_commit="$(git show --format="%H" --no-patch)"
        echo "git_commit is $git_commit"
        git_commit_short="$(git show --format="%h" --no-patch)"
        echo "git_commit_short is $git_commit_short"
        echo "GIT_COMMIT=$git_commit" >> $GITHUB_ENV
        echo "GIT_COMMIT_SHORT=$git_commit_short" >> $GITHUB_ENV


    # !!! Ideally this would use the same step that clients can use to build
    # the system with `make.sh`.  Unfortunately, something about the GitHub
    # Ubuntus do not like the old bootstrap executable.  Make sure the
    # ordinary path works, but for the moment patch over it just to get
    # to a point where the action works.
    #
    - name: Fetch R3 To Use For "Prep" Build Steps as $R3MAKE
      run: |
        repo_dir=$(pwd)/
        source tools/bash/fetch-prebuilt.sh
        r3make=$(fetch_prebuilt)
        echo "R3MAKE is set to $r3make"
        echo "But that executable won't run on GitHub for some reason"
        # "$r3make" --do "print {TESTING 1 2 3}"  # NOT WORKING, dunno why
        cd prebuilt
        wget http://hostilefork.com/media/shared/github/r3-linux-dec-2020
        chmod +x r3-linux-dec-2020
        r3make=$(pwd)/r3-linux-dec-2020
        echo "So now R3MAKE is $r3make"
        echo "R3MAKE=$r3make" >> $GITHUB_ENV  # pass to next step


    # We are able to use either the makefile version of the build or the
    # fully Ren-C driven form with CALL.  Both should be tested, but right
    # now this is using the makefile version for the web builds.
    #
    - name: Perform Emscripten-Based Build To Make .wasm and .js Files
      run: |
        mkdir build
        cd build

        # !!! optimization is currently hardcoded in the web build config
        # files as `s`.  Review if `z` would be better (it cannot be passed
        # in the options here at time of writing, and would be ignored even
        # if it could be due to that ldflags config hardcoding).
        #
        "$R3MAKE" ../make.r \
            config=../configs/$CONFIG_FILE \
            target=makefile \
            standard=c \
            os_id=$OS_ID \
            debug=none \
            git_commit="$GIT_COMMIT" \
            rigorous=no \
            static=no \
            extensions=-

        make prep
        make folders
        make


  #### DEPLOY STEPS #########################################################

    # We only want to build pull requests, we do not want to upload them to
    # the AWS server.  Deployment should happen only once a commit has been
    # accepted and pushed to master.  And then, it should only be greenlit
    # (to be the version the web console uses) if it passes the smoke test in
    # a headless browser.
    #
    # Unfortunately...there's no particularly great way to exit the steps
    # cleanly now if it's only a pull request.  We can stop the steps, but
    # it would look like an error:
    #
    # https://github.com/actions/runner/issues/662
    #
    # So either we write one giant monolithic step, or every subsequent step
    # has to be qualified with an `if: github.ref == 'refs/heads/master'`.
    # Though the latter is not *ideal*, it's good enough for government work.
    #


    # Move build products into a directory corresponding to the OS_ID, to
    # mirror the directory layout of the travis bucket.
    #
    # The commit ID is included in the upload because the AWS bucket holds
    # many versions of the build products at once.  To ask the web console to
    # use a specific commit ID, say:
    #
    # http://hostilefork.com/media/shared/replpad-js/?git_commit=<<shorthash>>
    #
    # The .js file contains the loading and setup code, which includes "cwrap"
    # functions that offer friendly JS function interfaces that take types
    # like JS strings, instead of being limited to the "integer heap address
    # parameters only" nature of Wasm functions.
    #
    # The .wasm file bundles both the compiled C code for the interpreter and
    # memory image (C constants, including compressed mezzanine code).
    #
    # There used to be more files, but this has streamlined over time...and
    # the pthread build is no longer supported so there's no `.worker.js`.
    # The only remaining potential build products would be debug files.  (This
    # would change if extensions are built as their own "DLL"s.)
    #
    # Note: %load-r3.js is a weak link in the test-before-greenlight strategy.
    # There's not a way to select the singular loader, so any changes must be
    # deployed before we can test any build (even a non-"greenlit" one).
    #
    # !!! The repl could be adjusted to use an alternate load-r3.js, which
    # would mean not naming it statically in the HTML.  To keep file variants
    # from accruing in the root directory, it could use some constant second
    # name (like %load-r3-preflight.js).  Review.
    #
    - name: Rename Build Products To Include Commit ID
      if: github.ref == 'refs/heads/master'  # see notes on DEPLOY STEPS
      run: |
        new_name_with_commit="r3-${GIT_COMMIT_SHORT}"

        cd build
        ls -alF  # so you can see what was built
        mkdir ${OS_ID}  # where we put products to match Travis dir layout

        cp libr3.js "${OS_ID}/lib${new_name_with_commit}.js"
        cp libr3.wasm "${OS_ID}/lib${new_name_with_commit}.wasm"

        # (not in subdir of 0.16.x because loader needs to pick between them)
        # See note above about how changes to this file undermines greenlight
        #
        cp ../extensions/javascript/load-r3.js .


    # This action configures the AWS keys stored in GitHub's "Secrets" for
    # the repository so that `aws s3` allows us to do uploads, without needing
    # to publish any passwords publicly:
    #
    # https://github.com/aws-actions/configure-aws-credentials
    #
    - name: Configure AWS Credentials
      if: github.ref == 'refs/heads/master'  # see notes on DEPLOY STEPS
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.METAEDUCATION_AWS_ACCESS_KEY }}
        aws-secret-access-key: ${{ secrets.METAEDUCATION_AWS_SECRET_KEY }}
        aws-region: us-east-1


    # Here we upload the files to AWS, but we don't bump the special file
    # that is used by %load-r3.js to decide which library commit to use yet.
    #
    # We have to set the MIME type on .wasm files, or the browser will not
    # load them as .wasm (it uses a fallback mechanism that is slower)
    #
    # The upload() function is put in the environment so the greenlight step
    # has it available if it runs.
    #
    - name: Upload Files To AWS (Don't Bump Version Used By load-r3.js Yet)
      if: github.ref == 'refs/heads/master'  # see notes on DEPLOY STEPS
      run: |
        upload() {
          # Note that `;;` is specific to bash's `case`, unrelated to `;`
          case $1 in
            *.wasm) OPT_TYPE="--content-type application/wasm" ;;
            *) OPT_TYPE="" ;;
          esac
          rm -f _  # we round trip to a file called `_` to check for parity
          aws s3 cp $1 s3://${AWS_S3_BUCKET_NAME}/travis-builds/$1 $OPT_TYPE
          aws s3 cp s3://${AWS_S3_BUCKET_NAME}/travis-builds/$1 _
          if ( cmp $1 _ ); then
            echo === UPLOADED $1 ===
          else
            echo === UPLOAD $1 FAILED ===
            exit 1
          fi
        }

        cd build
        upload load-r3.js
        for i in $OS_ID/*; do upload $i; done


    # Check the deployment before "green-lighting" the %last-deploy.short-hash
    #
    # We do this currently in the web builds with a "headless" Firefox (e.g.
    # no GUI Window), automated through the Python's `marionette_driver`:
    #
    # https://firefox-source-docs.mozilla.org/python/marionette_driver.html
    #
    # The Marionette httpd server for control exists only in Firefox (with
    # a default port 2828) and is only enabled if you use `-marionette`.
    #
    # https://vakila.github.io/blog/marionette-act-i-automation/
    #
    # Comparable-but-incompatible APIs to control running browsers exist for
    # Chrome and others.  The W3C's "WebDriver" initiative standardizes a
    # "ODBC for browser control" which translates a common API into calls
    # with plugins for each particular browser.  The layer is bulky and is
    # typically used with "Selenium" which is even bulkier.  To be lighter
    # we just use Python with raw Marionette.
    #
    # Long term we might have to do more than this simple test, but in the
    # 80/20 rule it's going to deliver on catching most of the breakages.
    #
    # !!! WebSocket support in Ren-C would allow avoiding this Python usage.
    # It is "planned for the future".  :-/
    #
    - name: Test ReplPad Against Uploaded Lib By Running In Headless Firefox
      if: github.ref == 'refs/heads/master'  # see notes on DEPLOY STEPS
      run: |
        sudo apt-get install net-tools  # for netstat, diagnose network issues

        pip3 install marionette-driver --user  # Python Install Package

        # Create a Firefox profile in the current directory that we can tweak
        # (as finding the default one's auto-generated name is a pain)
        #
        firefox -headless -CreateProfile "ff-profile $(pwd)/ff-profile"

        # The way to set `about:config` flags in preferences is via %user.js
        #
        # https://askubuntu.com/a/313662/137769
        # http://kb.mozillazine.org/User.js_file
        #
        # The Marionette port for control defaults to 2828, and can be
        # overridden on the command line by `--marionette-port <port>`.  But
        # to show another place to set it, here's the profile setting.
        #
        # Yaml and HereDoc aren't always compatible, so we use plain ECHO
        # instead to make our user.js file:
        #
        # https://en.wikipedia.org/wiki/Here_document#Unix_shells
        # https://travis-ci.community/t/2756
        {
            # !!! At one time we turned on shared_memory for the pthreads
            # build.  But the pthreads build has been scrapped.  There's not
            # really a need to turn shared memory off, but do it just to show
            # another setting...and that we don't require it.
            #
            echo "user_pref(\"javascript.options.shared_memory\", false);"
            echo "user_pref(\"marionette.port\", 2828);"  # should be default
        } > $(pwd)/ff-profile/user.js

        # We keep the Python test script for the browser build in the GitHub
        # replpad-js repository.  Fetch it.
        #
        wget https://raw.githubusercontent.com/hostilefork/replpad-js/master/tests/test-repl-ff.py

        # Start Firefox headless with the marionette automation enabled
        # (the `&` starts it in the background)
        #
        firefox -headless --profile ff-profile -marionette  &
        sleep 5  # Give Firefox time to spin up (should be in cache now)

        echo "Running netstat -lntu: Marionette should be listening on 2828"
        netstat -lntu
        ps aux | grep firefox

        # Run the script.  The result will be 0 if the test was sucessful.
        # Note that we ask the REPL to be instantiated with the libr3.js we
        # just uploaded that has not been "greenlit" by uploading the
        # `last-deploy.short-hash`...so we must pass the current commit in
        # explicitly to be asked for in the URL.
        #
        python3 test-repl-ff.py --shorthash "${GIT_COMMIT_SHORT}"


    # Each ${OS_ID} directory contains several builds for recent commits.
    # Since they are served statically from S3, we don't have a query to
    # serve the most recent one that successfully built (based on a date
    # or other property).  So we write a file with a fixed name in that
    # directory to identify the last build...it can be obtained via a
    # CORS fetch() request.
    #
    # However, the upload might take a while...or fail part way through.
    # Hence, we make this the last file uploaded--so that when the browser
    # tries to fetch files for that ID, they'll all be there.
    #
    - name: Greenlight Build for load-r3.js To Use If Tests Passed
      if: github.ref == 'refs/heads/master'  # see notes on DEPLOY STEPS
      run: |
        cd build
        local=${OS_ID}/last-deploy.short-hash

        # -n option to echo means "no newline at end" (it's not a "text file"
        # so there is no standard enforcing that it have one...and it's
        # easier in the client to not have it)
        #
        echo -n "${GIT_COMMIT_SHORT}" > $local

        remote=s3://${AWS_S3_BUCKET_NAME}/travis-builds/$local
        aws s3 cp $local $remote  # upload
